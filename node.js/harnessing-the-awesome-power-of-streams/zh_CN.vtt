WEBVTT

00:00.001 --> 00:03.075
大家请看我的大屏幕

00:03.075 --> 00:08.340
好，今天我要和大家聊聊：如何充分利用stream的超强威力

00:08.340 --> 00:12.790
我觉得stream是Node中最未被充分利用的一部分

00:12.790 --> 00:17.325
但总体说来，却正是stream，赋予了Node以及JavaScript不可思议的魔力

00:17.325 --> 00:22.095
回到六十年代，这里要反复强调

00:22.095 --> 00:23.885
不，别想了，闭嘴！（台下不知发生何事）

00:23.885 --> 00:31.555
好，回到六十年代，有个叫Doug……，事实上重音不能在“I”上

00:31.555 --> 00:34.490
有个叫Doug McIlroy的家伙

00:34.490 --> 00:42.030
貌似，貌似，将文件夹摔在地上（随便吧，不重要），怒斥道：

00:42.030 --> 00:46.420
不行，Unix必须得有Stream，否则老子TMD就不干了

00:46.420 --> 00:49.985
酷毙了，归功于这个“疯子”，我们现在有了Stream

00:49.985 --> 00:55.455
简单来说，stream视程序为一段段代码片段

00:55.455 --> 00:58.830
就好比是花园中的软管，可以拼接在一起

00:58.830 --> 01:01.915
我觉得这里用软管拼接的比喻相当贴切

01:01.915 --> 01:04.435
首先要介绍的第一种stream是readable stream

01:04.435 --> 01:08.980
readable stream其实就是事件提供商（event vendor），产生data事件和end事件

01:08.980 --> 01:10.645
也许不止如此，不过那些都不重要

01:10.645 --> 01:17.120
我们来举个readable stream的例子

01:17.120 --> 01:19.525
vi start.js(备注: 用vi编辑器打开start.js文件)

01:19.525 --> 01:23.290
ok，首先要做的，也许你见过

01:23.290 --> 01:29.155
我们用fs.createReadStream，我这里有个字典文件，里面有很多单词

01:29.155 --> 01:35.120
然后，可以用pipe，就好比Unix中将stderr pipe到stdout

01:35.120 --> 01:42.770
然后，执行它，酷！所有的单词都在stdout打印出来了

01:42.770 --> 01:50.715
stream真正酷的地方在于，你知道吗，不需要将所有的数据先全部载入到内存中。而是会一段段数据不间断地输出

01:50.715 --> 01:56.310
在stream中，这真的很酷，因为（执行）结果就好像是即时获得的

01:56.310 --> 02:05.285
除此之外，你还可以写出更加有意思的程序，比方说，如果不想让stream在stdout上写完数据后退出的话，
可以使用{end: false}

02:05.285 --> 02:11.145
相比用stream而言，自己写一个stream有些许复杂

02:11.145 --> 02:16.210
对于readable stream，首先要做的，代码有少许改变，不过不用太担心，也不用去强记

02:16.210 --> 02:19.780
首先要做的就是将readable属性设置为true

02:19.780 --> 02:25.646
这里就是这个简单例子所有的代码：它分发data事件，（数据）就是一个计数器

02:25.646 --> 02:30.950
如果运行5.js文件

02:30.950 --> 02:35.560
酷！在屏幕最下方，能看到一串无限长的数字

02:35.560 --> 02:38.520
并且输出速度越来越快，这是因为数字越来越多

02:38.520 --> 02:49.370
不过，如果想要在两秒钟后停止的话，我们只要分发end事件即可

02:49.370 --> 02:52.290
好了，一秒、两秒，结束！

02:52.290 --> 03:00.385
酷！除了能够pipe数据之外，真正酷的还在于

03:00.385 --> 03:04.960
我们还能从头开始创建writable stream

03:04.960 --> 03:11.155
如果你对Node很熟悉，你或许（我也希望）对下面的代码很熟悉

03:11.155 --> 03:14.760
fs.createWriteStream, 赞~

03:14.760 --> 03:18.250
因为，剩下的就是往stream里面写数据

03:18.250 --> 03:27.595
由于这里已经是一个文件了，就没有像用一个大stream或者大的buffer来将
后续的数据拼接起来的必要了

03:27.595 --> 03:35.185
你只需……，好了，如果运行该程序，并cat output.txt（查看文件内容）

03:35.185 --> 03:39.235
噢，酷！数据结果一样

03:39.235 --> 03:48.125
还有一个很酷的就是：你可以将像process.stdin这样的readable stream视作标准的readable stream
并将其pipe给writable stream

03:48.125 --> 03:50.720
如果运行2（.js）文件

03:50.720 --> 03:58.840
abc, def, 查看output.txt文件就会发现，其内容和我们输入的完全一致
和我们预期的一样

03:58.840 --> 04:04.330
从头开始创建这类writable stream有点难度

04:04.330 --> 04:06.145
首先，将writable属性设置为true

04:06.145 --> 04:12.665
这个属性是pipe内部使用的，这样我们就能process.stdin.pipe到writable stream了

04:12.665 --> 04:17.810
我们有了writable stream，并设置了end函数，在Node中，此处要注意（选中的代码行）

04:17.810 --> 04:20.985
这只是种约定，你也可以调用end函数，并传入一个对象

04:20.985 --> 04:27.550
我们调用.write，记得这里要留意下

04:27.550 --> 04:31.025
不过，如果使用一些第三方库的话，就没有这个问题了（库一般会处理掉）

04:31.025 --> 04:42.410
好了，如果运行该程序，就能做类似的事情：将所有输入的内容打印出来

04:42.410 --> 04:47.520
如果结束stream，就能看到一个end!的提示消息

04:47.520 --> 04:52.690
超酷！事实上，我们可以利用自定义writable stream做更有用的事情

04:52.690 --> 04:57.480
比方说，我们来统计输入的字节数，并在stream结束时，将结果输出到stdout

04:57.480 --> 05:06.045
代码就在这里，首先从0开始，并且每次都加上buf.length，最后，输出字节总数

05:06.045 --> 05:16.080
运行该程序，abc，def，好，结束！结果输出字节总数为8
因为每行还有一个换行符（一行就是4个），酷！

05:16.080 --> 05:18.885
好了，这就是writable stream

05:18.885 --> 05:23.360
下面要介绍的非常重要

05:23.360 --> 05:30.245
这是一个从Dominictarr借鉴过来的想法（概念）

05:30.245 --> 05:34.720
叫做through stream，through stream是readable writable stream

05:34.720 --> 05:40.005
它也并非是唯一的一种readable writable stream，不过，它工作方式像
readable writable stream（像过滤器（filter））

05:40.005 --> 05:46.785
举例来说，就好比是Unix中的grep，grep你应该知道吧，
它接收stdin作为输入，做一些处理之后，将结果输出到stdout

05:46.785 --> 05:48.845
就好像：从这里到那里

05:48.845 --> 05:55.645
下面就让我们来实践下，我们创建一个新的stream，并将readable和writable都设为true

05:55.645 --> 05:57.585
结合前两个例子

05:57.585 --> 06:00.885
我们可以拥有一个write stream，但同时还可以分发data事件

06:00.885 --> 06:06.790
很酷吧！这里，我将输入的字符以大写形式输出，以此来形成一个“扩音”stream的效果

06:06.790 --> 06:10.925
效果会很明显，对于end函数，我们处理和先前保持一样

06:10.925 --> 06:17.910
接下来，将stdin pipe到ts，ts效果类似ls

06:17.910 --> 06:24.650
好了，运行3.js，abc，hello lisboa，然后结束！

06:24.650 --> 06:27.805
噢，不！噢，对，我忘记pipe了

06:27.805 --> 06:33.920
好吧，此前，代码是这样的，事实上，这里还需要讲ts pipe到输出源

06:33.920 --> 06:43.045
好了，现在有了4.js，输入：beep boop 然后结束
输出了大写形式的消息

06:43.045 --> 06:46.425
太棒了！这就是through stream

06:46.425 --> 06:49.815
好，这是writable stream、这是through stream

06:49.815 --> 06:52.441
这是一张我自己画的图，来解释刚刚发生的一切

06:52.441 --> 06:57.485
中间有个函数，两端是两个可互相转换的机器

06:57.485 --> 07:02.380
接下来要介绍的内容我觉得也很重要：pause stream

07:02.380 --> 07:05.540
pause stream也是一类through stream

07:05.540 --> 07:12.885
在Node中，pipe内部有一种机制，可以让你处理后续数据

07:12.885 --> 07:21.680
调用pause暂停，并当想要重新开始获取数据时，就调用.resume，
就好比是出水口有个阀门，关闭就不出水，打开就出水

07:21.680 --> 07:25.525
可以用水管互相连接来做比喻，如果这有助于理解的话

07:25.525 --> 07:28.855
这里有一个pause stream的例子

07:28.855 --> 07:30.155
我们来看下

07:30.155 --> 07:41.645
这是一个http服务器，它将我们的输入都写到output.txt文件

07:41.645 --> 07:46.740
我首先echo beep boop，接着用curl，最后运行该程序

07:46.740 --> 08:02.180
node 0.js，接着输入curl -sSNT- localhost:3000
看到了ok

08:02.180 --> 08:07.510
现在，输入的内容应当已经通过writable stream写到output.txt文件中了

08:07.510 --> 08:10.110
好，我们cat出来看看，酷！看到了！

08:10.110 --> 08:15.555
超赞！但是，假设这个时候需求变更了

08:15.555 --> 08:19.560
假设现在要在写数据前需要先创建一个文件夹

08:19.560 --> 08:24.595
这个时候，我们就不得不调用fs.mkdir，并用一个随机的id来表示文件夹名字

08:24.595 --> 08:29.645
所以，这段代码用来生成id，并将fs.mkdir放在这里

08:29.645 --> 08:34.465
好，应该差不多了，对吧？

08:34.465 --> 08:43.220
唔，看下，同样的，这里不再是res.end('ok')，而是以id结束

08:43.220 --> 08:47.540
好，结果应该是，哦不，貌似写多文件了

08:47.540 --> 08:51.075
node 2.js, 就是它!

08:51.075 --> 09:00.785
好，node 2.js，ok，酷！结果显示了id，数据就应该在数据目录下的output.txt文件中了

09:00.785 --> 09:04.920
尼玛，居然是空的！怎么回事？

09:04.920 --> 09:08.270
我们再来试下，也许这次就好了

09:08.270 --> 09:17.240
好，果然好了！有点诡异

09:17.240 --> 09:21.720
这并非“事故”，而是我们的代码有bug隐患

09:21.720 --> 09:27.970
我们先调用fs.mkdir，然后pipe到writable stream

09:27.970 --> 09:35.510
问题来了，如果data事件在fs.mkdir的回调前就分发了，就会出现问题

09:35.510 --> 09:37.895
那么怎么解决这个问题呢？答案当然是 pause stream

09:37.895 --> 09:46.300
我们只要稍微改下代码，就……

09:46.300 --> 09:51.035
好，首先咱们要引入一个叫pause-stream的模块

09:51.035 --> 09:53.450
然后，创建一个pause stream，将其暂停

09:53.450 --> 09:59.460
然后，这次不是将request pipe给ws对象

09:59.460 --> 10:10.695
而是pipe给…… ps.pipe，让我先回到上个版本

10:10.695 --> 10:13.780
好，我们pipe pause stream而不是write stream

10:13.780 --> 10:21.025
它暂停了，随后，在最后，回调函数触发后，我们调用resume来恢复stream

10:21.025 --> 10:27.520
在恢复stream的时候，也许数据已经过来了，也许还没有。pause stream会将数据buffer起来

10:27.520 --> 10:35.750
继续刚刚这个例子，这次运行更新后的版本，然后用curl

10:35.750 --> 10:40.660
再看看output文件，确认没错，这次对了

10:40.660 --> 10:44.340
你可能已经注意到了，服务器会返回id

10:44.340 --> 10:49.725
所以，事实上，我们可以使用Unix的聚合（aggregator），来打印output.txt中的数据

10:49.725 --> 10:53.470
好，这就在输出文件内容

10:53.470 --> 10:57.840
如你所见，现在每次都能够获得正确的输出结果

10:57.840 --> 11:01.715
上述就是使用pause stream来规避此前获取数据的问题

11:01.715 --> 11:03.755
pause stream很赞

11:03.755 --> 11:11.650
好，下面要闪亮登场的是duplex stream

11:11.650 --> 11:14.355
duplex stream也是readable writable stream

11:14.355 --> 11:19.565
不过，duplex非常酷，因为它很想电话

11:19.565 --> 11:22.705
它不仅仅像through stream那样是一个过滤器（如grep）

11:22.705 --> 11:24.470
它更像是“谈话”

11:24.470 --> 11:29.395
比方说，A要和B通话，这个时候，B也需要和A通话

11:29.395 --> 11:33.170
就像这类循环的实时通讯

11:33.170 --> 11:38.610
如屏幕所示，a.pipe(b).pipe(a) 诸如此类

11:38.610 --> 11:41.610
也许，不，应该是你肯定用过duplex stream

11:41.610 --> 11:55.845
有个很好的模块叫duplexer，它衍生自event-stream模块

11:55.845 --> 12:02.545
它可以将readable stream和writable stream合成到一个duplex stream中

12:02.545 --> 12:06.605
从某种意义上来说，duplex可以说是stream之王

12:06.605 --> 12:13.360
特别是当你有一个request对象和response对象时，就可以将两者拼接起来，形成一个duplex stream

12:13.360 --> 12:22.665
这样很酷，因为你可以将其他的duplex stream以及request、response对象拼接在一起
再将其拼接到另外一个stream上，然后再拼回到duplex stream

12:22.665 --> 12:25.600
duplex真的超赞

12:25.600 --> 12:31.630
在后面会看到很多duplex stream，这里暂且先跳过

12:31.630 --> 12:37.440
好了，另外一种through stream，我一定，一定要介绍的，就是JSONStream

12:37.440 --> 12:38.985
JSONStream也超赞！

12:38.985 --> 12:48.025
假设这里有一个125Mb大的文件，包含了旧金山的所有的地界信息

12:48.025 --> 12:53.455
真的有这个文件哦，我花了将近3小时才搞定

12:53.455 --> 13:02.040
如果，我们“霸王硬上功”——直接讲其载入到内存中

13:02.040 --> 13:05.230
你非得等上一段很长的时间不可

13:05.230 --> 13:10.845
完全载入，也许得花上几分钟的时间，

13:10.845 --> 13:16.675
而如果我们这里发挥stream的威力，使用JSONStream模块的话

13:16.675 --> 13:18.790
会提升不少（时间短很多）

13:18.790 --> 13:24.230
回到stream，设置我们要获取的值

13:24.230 --> 13:37.215
是坐标（coordinates）属性，该属性在features键中，features中geometry键

13:37.215 --> 13:42.370
里面有coordinates键，coordinates键就是我们真正需要的数据

13:42.370 --> 13:50.675
那么，怎么做呢？我们用JSONStream，JSONStream.parse，该方法接收一个包含类似键/值形式的数组作为参数

13:50.675 --> 13:53.375
事实上不仅仅是键/值，还可以用一些模式等

13:53.375 --> 14:00.235
“features”是一个数组，所以，如果我们需要数组所有的元素，就可以简单的指定true即可，
无需将所有的名字列出来

14:00.235 --> 14:03.755
接下来是geometry键，然后是coordinates键

14:03.755 --> 14:11.860
我们只需用console.dir将值打印出来，并将一个read stream pipe给parser

14:11.860 --> 14:17.550
好了，运行该程序，也许少了一步

14:17.550 --> 14:23.590
噢，我还在pause stream的例子中，这就是为啥没有反应

14:23.590 --> 14:26.290
好，再次运行该程序，好，酷！

14:26.290 --> 14:37.405
和fs.readFile('citylots.json')不同，
我们不用将所有的数据都载入内存

14:37.405 --> 14:40.190
我们直接就可以处理

14:40.190 --> 14:44.910
非常酷吧，stream好样的！

14:44.910 --> 14:51.340
再来做些改动，假设我们这次需要从stream中读取数据，并将其写回到文件中

14:51.340 --> 14:58.715
没问题，我们可以用JSONStream.stringify
这和JSON的stringify类似，只是是stream的方式

14:58.715 --> 15:04.090
我们可以stringify.pipe 到一个write stream，这里就是coords.json文件

15:04.090 --> 15:11.220
好，我们运行9.js

15:11.220 --> 15:20.050
卡住了，这是因为正在往coords.json文件中写数据

15:20.050 --> 15:25.060
如果我们查看下文件内容的字数，就会发现在不断增长

15:25.060 --> 15:29.255
这是因为stream正在工作，我们不需要将整个一大坨数据加载到内存中

15:29.255 --> 15:32.285
这对于书写可伸缩的web服务而言，非常非常的重要

15:32.285 --> 15:35.105
尤其是写Node的时候，应当要非常擅长处理这类事情

15:35.105 --> 15:41.890
记得在适用的场景下，尽可能的使用JSONStream

15:41.890 --> 15:47.115
好，下一个要展示的，酷毙了的东西叫scuttlebutt

15:47.115 --> 15:52.245
scuttlebutt是……
哦，对了，dnode也属于duplex stream一例

15:52.245 --> 15:55.930
dnode会在后面我要展示的“碉堡”了的demo充当重要角色

15:55.930 --> 16:03.060
言归正传，scuttlebutt并非是指和水相关的装置

16:03.060 --> 16:11.900
这里的scuttlebutt是一种gossip协议，用来使得网络中不同节点间能够通讯

16:11.900 --> 16:17.570
它没有标准的数据源，而只是到处传递消息

16:17.570 --> 16:24.130
为了同步状态，这很酷，它属于一种基于历史的算法（history based algorithm）

16:24.130 --> 16:31.506
应该说这超赞，好，要使用scuttlebutt

16:31.506 --> 16:38.305
这里我只使用scuttlebutt模型，如果要看更多相关的例子，可以看一个叫crdt的模块

16:38.305 --> 16:43.470
通过scuttlebutt模型, 每个模型都可以创建stream

16:43.470 --> 16:50.981
这里，在A节点上设置一个值，并将它pipe给B节点

16:50.981 --> 17:01.185
运行该程序，酷！尽管我们是在节点A上设置的值，但是我们可以在节点B上捕获到事件

17:01.185 --> 17:04.835
这里我们只是pipe出去，事实上，我们可以将其用在网络连接上

17:04.835 --> 17:11.795
这里，创建一个http服务器，然后做些类似设置值，取值的操作

17:11.795 --> 17:20.035
这部分很酷，如果我……
第一个参数是端口号

17:20.035 --> 17:27.550
所以，我们监听8000端口，并利用curl向该端口发送http请求

17:27.550 --> 17:31.325
这条命令是获取键a的值（结果是undefined），这里还可以设置键a的值

17:31.325 --> 17:35.410
现在我获取到了键a的值为5，非常简单，想怎么设就怎么设，想设多少就设多少

17:35.410 --> 17:44.400
然而，如果我再起一台服务器，监听8001端口，并将其通过scuttlebutt和8000端口上的服务器相连

17:44.400 --> 17:50.455
这时，我就能通过curl localhost:8001/a 也能获取到a的值，当然，还可以通过8001上的服务器给a设置新值

17:50.455 --> 17:54.855
然后再从8000端口上的服务器获取a的值，也获得了最新的值

17:54.855 --> 17:59.605
很酷吧，不过远不止如此，我们并非只能连接客户端-服务器端

17:59.605 --> 18:10.010
事实上，还可以连接……这里，我新起一台监听8002的服务器，但，我只将其和8001端口上的服务器相连

18:10.010 --> 18:19.755
这是，如果我尝试获取……，如果我在8002上设置a的值

18:19.755 --> 18:24.365
随后在8000上获取它，应该能够获取到相同的值，哈哈，如我所言！

18:24.365 --> 18:33.940
这是因为……，8002端口上的服务器并没有直接和8000端口上的服务器相连，它只和8001上的相连

18:33.940 --> 18:40.705
好，简单来说，只要stream互相之间能够连通

18:40.705 --> 18:43.605
那么整个网络中结点的状态最终都会同步

18:43.605 --> 18:46.020
你只需要在此处设置，就能随时从彼处取值

18:46.020 --> 18:51.865
无需担心，类似于如何同步客户端和服务端、如何保证数据库cluster结点间如何做数据一致

18:51.865 --> 18:58.740
好，下面将全面进入下一部分，那就是……（跳过这里）

18:58.740 --> 19:02.690
这部分非常精彩

19:02.690 --> 19:06.865
不用担心，我会很快给大家演示，保证让你们目瞪口呆

19:06.865 --> 19:13.910
我们来构建一个streaming web应用，该应用功能如下：同步所有用户的状态；

19:13.910 --> 19:16.105
监听服务器端事件；rpc控制接口；

19:16.105 --> 19:19.515
通过mux-demux在node端和浏览器端运行多个stream；

19:19.515 --> 19:24.840
并且在多台web服务器之间做负载均衡，使用scuttlebutt（gossip协议）

19:24.840 --> 19:28.105
好了，听起来很赞吧，那就开始吧

19:28.105 --> 19:32.210
首先要做的就是创建一个scuttlebutt模型，并创建一个web服务器

19:32.210 --> 19:35.940
这里，web服务器就只监听在（指定的）端口

19:35.940 --> 19:41.265
嗯？什么情况？可能是太快了

19:41.265 --> 19:46.760
好了，我们创建一个web服务器，创建一个stream

19:46.760 --> 19:50.785
接下来，我们只需在这里加一样东西

19:50.785 --> 19:56.010
知道couchdb吧，它的api很赞，不过，我们能做的更赞，那就是

19:56.010 --> 20:00.490
就像是服务器和客户端连接

20:00.490 --> 20:07.005
但，我们这里，任何人都可以连接到我们的服务器，复制状态，这里不仅仅是从我们这里复制，还能复制给我们

20:07.005 --> 20:13.055
状态信息会通过streams，在整个网络间传递，这简直酷毙了

20:13.055 --> 20:23.895
好，另外，我们还要用到一个我写的叫emit-stream的模块，用来将事件分发器和stream进行互相转化

20:23.895 --> 20:31.085
我们还会用到此前提过的，叫mux-demux的模块，这个模块很赞

20:31.085 --> 20:37.305
它能将多个stream，封装成一个stream，我画了一张图来对其做解释说明

20:37.305 --> 20:43.520
这是emit-stream，我的图片在哪里？好吧，它肯定在，不管了，没关系

20:43.520 --> 20:50.810
好，我们有了mux-demux，它就像一个神物

20:50.810 --> 20:56.790
通过mux-demux，我们创建一个名为state的stream，用来做同步

20:56.790 --> 21:00.375
我们再创建另外一个叫events的stream用于系统事件

21:00.375 --> 21:05.770
它会将事件分发器转变为stream，在另一端则将stream变为事件分发器，反之亦然

21:05.770 --> 21:12.815
好，酷！另外要做的就是分发事件

21:12.815 --> 21:19,615
当请求结束时，我们分发“part”事件，有意思吧

21:19,615 --> 21:21.805
这部分真心赞！

21:21.805 --> 21:26.080
看这里，我们将字符串切割成数组

21:26.080 --> 21:32.940
现在，所有端口号之后额外的参数

21:32.940 --> 21:37.800
都指定了和其他参数端口上web服务器相连接

21:37.800 --> 21:40.315
所以，我们只要起多台web server，它们互相之间都会通讯

21:40.315 --> 21:46.555
它们使用gossip协议来通讯，所有服务器之间的状态都会同步

21:46.555 --> 21:50.850
这部分代码可以直接放到浏览器端，下部分会介绍

21:50.850 --> 21:55.830
登录之后，对，这就是我们的web服务器

21:55.830 --> 22:06.090
我们可以用shoe，这也是我自己写的模块，它其实就是讲sockjs做了封装，提供了stream功能

22:06.090 --> 22:13.855
它干的就这么多。但却很酷，你无需关心旁枝末节，用模块就是，来吧

22:13.855 --> 22:22.250
好了，stream准备就绪，我们还需要做的复制工作就是stream.pipe(createStream()).pipe(stream)

22:22.250 --> 22:29.445
这是mux-demux连接，这和我们http streaming连接是一样的，都是用来复制（不同结点间）状态的

22:29.445 --> 22:36.385
好了，我们写了一个函数，用于创建stream，然后，用它在任何地方（浏览器、服务器/其他服务器）来复制状态

22:36.385 --> 22:40.060
我们只需要发送数据即可，轻松愉快，接下来的事情，网络间不同结点会自动同步

22:40.060 --> 22:44.955
这里还有一件事情

22:44.955 --> 22:50.545
这个例子中还用了dnode，理由就是：为什么不用呢？！

22:50.545 --> 22:54.465
这里，用dnode定义了一个函数

22:54.465 --> 23:01.275
有了mux-demux，我要做的就是再创建一个stream，将它pipe出去

23:01.275 --> 23:08.125
好了，完工！简单回顾下

23:08.125 --> 23:10.535
我们有dnode stream、mux-demux

23:10.535 --> 23:14.095
这里是浏览器部分的代码，用来渲染

23:14.095 --> 23:21.125
它负责绘制一个蓝色的大盒子，这里很酷的地方在于，我们用了同样的模块

23:21.125 --> 23:25.545
要不是这里有document.body这样的代码，恐怕很难看出这是浏览器端的代码吧

23:25.545 --> 23:28.710
我们用了scuttlebutt、mux-demux

23:28.710 --> 23:31.725
这些都是在浏览器端用哦~，还有emit-stream也不例外

23:31.725 --> 23:35.040
除了dom操作部分的代码，其余代码几乎完全一样

23:35.040 --> 23:41.645
好了，以上就是简单的代码回顾，等下我会运行这个例子，然后……就没有然后了（结束了）

23:41.645 --> 23:46.980
我们同步所有用户状态、用emit-stream监听服务器端事件

23:46.980 --> 23:51.465
通过mux-demux运行多个streams，以及在不同服务器间做负载均很

23:51.465 --> 23:55.430
这里还缺一个

23:55.430 --> 24:02.460
浏览器这边，我们用dnode来实现rpc接口调用，好了，全部完成

24:02.460 --> 24:07.625
让我们来启动这个“怪物”吧

24:07.625 --> 24:16.010
首先要browserify最新版本代码

24:16.010 --> 24:28.090
staticbundle.js，启动服务器并监听8000端口

24:28.090 --> 24:34.380
酷！可以访问了，HOLA LISBOA, 这是dnode在工作

24:34.380 --> 24:39.395
这里我们就只有一个盒子而已，还不够炫

24:39.395 --> 24:41.720
能做的就是拖拽，对吧？

24:41.720 --> 24:50.865
但是，当另外一个用户进来之后，我把它缩小点

24:50.865 --> 24:56.050
好，如果我把盒子移到这里，酷~~，如果从这里移动到那里

24:56.050 --> 24:59.570
也许你已经闻到了socket.io的味道了吧，这很赞，重用性很高

24:59.570 --> 25:02.115
不过，这还不够有趣

25:02.115 --> 25:06.520
让我们来点负载均衡

25:06.520 --> 25:16.785
我们在8001端口起一台服务器，并通过stream，将其和8000端口上的服务器相连

25:16.785 --> 25:23.720
噢，我的天！有些小bug，哦，不，求你了，工作吧，工作吧！

25:23.720 --> 25:33.640
我发誓它之前是好的，貌似……，噢，好了，工作了，尽管有些小瑕疵

25:33.640 --> 25:34.965
尽管有bug，不过意思到了，这里就是展现一种思路和想法

25:34.965 --> 25:44.765
好了，这就是我要讲的所有内容，我们再来看些描述模块的图片，它们真的非常赞

25:44.765 --> 25:55.730
谢谢！
